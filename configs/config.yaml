rag:
  enabled: true
  indexPath: "./docs/rag/moe_samples.json"
  gradeBand: "primary"
  subjects:
    - "math"
    - "english"
  maxChunks: 3
  includeSources: true
  sourceTypes:
    - "syllabus"
    - "past-paper"

llm:
  mode: "cloud"
  local:
    # LLM backends (pick ONE; the options are mutually exclusive).
    # Common settings:
    llamaServerUrl: "http://127.0.0.1:8080" # used by llama.cpp
    ctx: 2048
    temperature: 0.2
    # Option 1: llama.cpp with Llama 3 GGUF
    # backend: "llama.cpp"
    # model: "local"
    # modelPath: "/opt/models/llama/llama-3.gguf"
    # Option 2: llama.cpp with Qwen3 1.7B GGUF (Q8_0)
    backend: "llama.cpp"
    model: "local"
    modelPath: "/opt/models/llama/qwen3-1.7b-q8_0.gguf"
    # Option 3: LLM-8850 Qwen3 service (change api.port if it uses 8000)
    # backend: "llm8850"
    # llm8850:
    #   host: "http://127.0.0.1:8000"
    #   temperature: 0.2
    #   topK: 40
    #   requestTimeoutMs: 10000
    #   pollIntervalMs: 200
    #   maxWaitMs: 60000
    #   enableThinking: true
    #   resetOnRequest: true
  cloud:
    provider: "openai"
    apiKeyEnv: "OPENAI_API_KEY"
    model: "gpt-4o"
    baseUrl: "https://api.openai.com/v1"
    temperature: 0.2
    maxTokens: 256
    requestTimeoutMs: 10000

stt:
  mode: "cloud"
  backend: "whispercpp"
  whispercpp:
    binPath: "/usr/local/bin/whisper-cpp-main"
    modelPath: "/opt/models/whisper/ggml-medium.bin"
    language: "auto"
  cloud:
    provider: "openai"
    apiKeyEnv: "OPENAI_API_KEY"
    model: "whisper-1"
    baseUrl: "https://api.openai.com/v1"

tts:
  mode: "cloud"
  backend: "piper"
  piper:
    binPath: "/usr/bin/piper"
    voicePath: "/opt/models/piper/en_US-amy-medium.onnx"
    outputSampleRate: 22050
    # Optional Chinese voice (download separately).
    voicePathZh: "/opt/models/piper/zh_CN-huayan-medium.onnx"
    outputSampleRateZh: 22050
    # Optional per-language voices (override defaults).
    voiceByLang:
      en:
        voicePath: "/opt/models/piper/en_US-amy-medium.onnx"
        outputSampleRate: 22050
      zh:
        voicePath: "/opt/models/piper/zh_CN-huayan-medium.onnx"
        outputSampleRate: 22050
  cloud:
    provider: "openai"
    apiKeyEnv: "OPENAI_API_KEY"
    model: "tts-1"
    baseUrl: "https://api.openai.com/v1"
    voiceId: "alloy"

vision:
  enabled: true
  capture:
    backend: "rpicam-still"
    stillArgs:
      - "--width"
      - "1280"
      - "--height"
      - "720"
      - "--quality"
      - "90"
  ocr:
    enabled: false
    timeoutMs: 3000

audio:
  input:
    backend: "node-record-lpcm16"
<<<<<<< HEAD
    device: "plughw:CARD=KAYSHUDA,DEV=0"
=======
    device: "plughw:CARD=SP300U,DEV=0"
>>>>>>> 08e63fe (updating config)
    sampleRate: 16000
    channels: 1
    recordSeconds: 4
    arecordPath: "arecord"
  output:
    backend: "aplay"
<<<<<<< HEAD
    device: "plughw:CARD=KAYSHUDA,DEV=0"
    aplayPath: "aplay"

runtime:
  pushToTalkMode: "mhs-display"
=======
    device: "plughw:CARD=SP300U,DEV=0"
    aplayPath: "aplay"

runtime:
  pushToTalkMode: "api"
>>>>>>> 08e63fe (updating config)
  cameraIndicator: true
  micIndicator: true
  agents:
    enabled:
      - "tutor"
    # default: "tutor"
  # detectorTimeoutMs: 1500
  ui:
<<<<<<< HEAD
=======
    mode: "hold"
  whisplay:
>>>>>>> 08e63fe (updating config)
    mode: "hold"
    title: "Aceceed Edge"
  vision:
    triggerKeywords:
      - "read"
      - "see"
      - "check"
      - "worksheet"
      - "drawing"
    requirePaperForOcr: true

api:
  host: "0.0.0.0"
  port: 8000 # change if LLM-8850 uses 8000

logging:
  level: "info"
